{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Support Vector Machine (SVM), and how does it work?"
      ],
      "metadata": {
        "id": "ubaViQsIENGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Support Vector Machine (SVM) is a powerful supervised machine learning algorithm used primarily for classification, though it can also handle regression tasks. Here's how it works:\n",
        "\n",
        "How It Works\n",
        "- Linear SVM:\n",
        "\n",
        "  - Finds a straight hyperplane that separates classes with the largest possible margin.\n",
        "\n",
        "- Non-linear SVM:\n",
        "\n",
        "  - Uses kernel functions (e.g., polynomial, RBF) to transform data into a higher-dimensional space where a linear separator is possible.\n",
        "\n",
        "- Optimization:\n",
        "\n",
        "  - Solves a convex optimization problem to find the hyperplane with maximum margin while minimizing classification error."
      ],
      "metadata": {
        "id": "nn2StOQnEOcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the difference between Hard Margin and Soft Margin SVM."
      ],
      "metadata": {
        "id": "CqsWNJNaEg_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between Hard Margin and Soft Margin SVM lies in how strictly the algorithm separates the classes and handles misclassified data points.\n",
        "\n",
        "Hard Margin SVM\n",
        "- Definition: Assumes that the data is perfectly linearly separable.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - Finds a hyperplane that separates the classes without any errors.\n",
        "\n",
        "  - No data points are allowed inside the margin or on the wrong side of the hyperplane.\n",
        "\n",
        "- Limitation:\n",
        "\n",
        "  - Very sensitive to noise and outliers.\n",
        "\n",
        "  - Often impractical for real-world datasets that aren't perfectly separable.\n",
        "\n",
        "  Soft Margin SVM\n",
        "- Definition: Allows some misclassifications to achieve better generalization.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - Introduces a slack variable to permit violations of the margin.\n",
        "\n",
        "  - Balances between maximizing the margin and minimizing classification error.\n",
        "\n",
        "  - Controlled by a regularization parameter\n",
        "ùê∂\n",
        ":\n",
        "\n",
        "  - Low\n",
        "ùê∂\n",
        ": wider margin, more tolerance for misclassification.\n",
        "\n",
        "  - High\n",
        "ùê∂\n",
        ": narrower margin, less tolerance for misclassification."
      ],
      "metadata": {
        "id": "TpVFiMpWEinH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the Kernel Trick in SVM? Give one example of a kernel and\n",
        "explain its use case."
      ],
      "metadata": {
        "id": "72Bx20LaFToe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Kernel Trick is a clever mathematical technique used in Support Vector Machines (SVMs) to handle non-linearly separable data without explicitly transforming it into higher dimensions.\n",
        "\n",
        "Example: Radial Basis Function (RBF) Kernel\n",
        "Formula:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "- Use Case: Ideal for datasets where the decision boundary is non-linear and complex, such as:\n",
        "\n",
        "  - Image classification\n",
        "\n",
        "  - Bioinformatics (e.g., gene expression data)\n",
        "\n",
        "  - Anomaly detection\n",
        "\n",
        "- Benefits of the Kernel Trick\n",
        "  - Enables SVMs to solve complex problems without high computational cost.\n",
        "\n",
        "  - Makes SVMs extremely flexible and powerful for both classification and regression."
      ],
      "metadata": {
        "id": "EFdSPJV-FYqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is a Na√Øve Bayes Classifier, and why is it called ‚Äúna√Øve‚Äù?"
      ],
      "metadata": {
        "id": "sFkiJ4onFzM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Na√Øve Bayes Classifier is a simple yet powerful probabilistic machine learning algorithm used for classification tasks. It‚Äôs based on Bayes‚Äô Theorem, which calculates the probability of a class given a set of features.\n",
        "\n",
        "What Is Na√Øve Bayes?\n",
        "It predicts the class of a data point by computing the posterior probability:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "In practice, it simplifies to:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "- This simplification assumes conditional independence between features given the class label.\n",
        "\n",
        "Why Is It Called ‚ÄúNa√Øve‚Äù?\n",
        "- The algorithm assumes that all features are independent of each other ‚Äî a strong and often unrealistic assumption in real-world data.\n",
        "\n",
        "- Despite this ‚Äúna√Øve‚Äù assumption, it performs surprisingly well in many applications like:\n",
        "\n",
        "  - Spam filtering\n",
        "\n",
        "  - Sentiment analysis\n",
        "\n",
        "  - Document classification"
      ],
      "metadata": {
        "id": "kf6ZtxnFF6wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Describe the Gaussian, Multinomial, and Bernoulli Na√Øve Bayes variants.\n",
        "When would you use each one?\n"
      ],
      "metadata": {
        "id": "X8eX6ySmGVeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Gaussian Na√Øve Bayes\n",
        "Assumption: Features follow a normal (Gaussian) distribution.\n",
        "\n",
        "Use Case: Best for continuous numerical data.\n",
        "\n",
        "Example: Predicting disease risk based on lab test results like blood pressure or cholesterol levels.\n",
        "\n",
        "- Why Use It?\n",
        "Simple and effective when features are real-valued and normally distributed.\n",
        "\n",
        "Common in medical, financial, and scientific datasets.\n",
        "\n",
        "2. Multinomial Na√Øve Bayes\n",
        "Assumption: Features represent discrete counts (e.g., word frequencies).\n",
        "\n",
        "Use Case: Ideal for text classification tasks.\n",
        "\n",
        "Example: Spam detection, sentiment analysis, document categorization.\n",
        "\n",
        "- Why Use It?\n",
        "Handles high-dimensional sparse data well.\n",
        "\n",
        "Works with bag-of-words or TF-IDF representations in NLP.\n",
        "\n",
        "3. Bernoulli Na√Øve Bayes\n",
        "Assumption: Features are binary (0 or 1).\n",
        "\n",
        "Use Case: Suitable for binary/boolean features.\n",
        "\n",
        "Example: Whether a word appears in a document (yes/no), or presence/absence of symptoms.\n",
        "\n",
        "- Why Use It?\n",
        "Useful when features are binary indicators.\n",
        "\n",
        "Often used in simple text classification with binary word presence."
      ],
      "metadata": {
        "id": "zJdQcjD0GXeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "‚óè Load the Iris dataset\n",
        "‚óè Train an SVM Classifier with a linear kernel\n",
        "‚óè Print the model's accuracy and support vectors.\n"
      ],
      "metadata": {
        "id": "22HR188IGpg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier with a linear kernel\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print support vectors\n",
        "print(\"Support Vectors:\")\n",
        "print(svm_model.support_vectors_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElxYGT1Gsdq",
        "outputId": "913f6849-a097-459e-9d22-e7f43423445c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Support Vectors:\n",
            "[[4.8 3.4 1.9 0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [4.9 2.5 4.5 1.7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "‚óè Load the Breast Cancer dataset\n",
        "‚óè Train a Gaussian Na√Øve Bayes model\n",
        "‚óè Print its classification report including precision, recall, and F1-score.\n"
      ],
      "metadata": {
        "id": "k2cv7pkyG4lR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Gaussian Na√Øve Bayes model\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_test, y_pred, target_names=data.target_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqpMdAZTG8DW",
        "outputId": "fcc8cff9-dd7f-4861-b215-c69b9307858d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.93      0.90      0.92        63\n",
            "      benign       0.95      0.96      0.95       108\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.94      0.93      0.94       171\n",
            "weighted avg       0.94      0.94      0.94       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "‚óè Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best\n",
        "C and gamma.\n",
        "‚óè Print the best hyperparameters and accuracy.\n"
      ],
      "metadata": {
        "id": "cshqCRoDHCWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid for C and gamma\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and evaluate accuracy\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADwKYhvkHGQi",
        "outputId": "45437847-0aef-412f-f91c-bcd7e761da2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Model Accuracy: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "‚óè Train a Na√Øve Bayes Classifier on a synthetic text dataset (e.g. using\n",
        "sklearn.datasets.fetch_20newsgroups).\n",
        "‚óè Print the model's ROC-AUC score for its predictions"
      ],
      "metadata": {
        "id": "DPoxSGbnHJIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Load a binary subset of the 20 Newsgroups dataset\n",
        "categories = ['sci.space', 'rec.sport.baseball']\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=categories)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(newsgroups.data)\n",
        "y = newsgroups.target\n",
        "\n",
        "# Binarize the labels for ROC-AUC\n",
        "y_binary = label_binarize(y, classes=[0, 1]).ravel()\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Multinomial Na√Øve Bayes classifier\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for ROC-AUC\n",
        "y_prob = nb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate and print ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u6vJCt-HRcp",
        "outputId": "4b2ef31e-fd5d-401d-b458-b6a0ec2c0446"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you‚Äôre working as a data scientist for a company that handles\n",
        "email communications.\n",
        "Your task is to automatically classify emails as Spam or Not Spam. The emails may\n",
        "contain:\n",
        "‚óè Text with diverse vocabulary\n",
        "‚óè Potential class imbalance (far more legitimate emails than spam)\n",
        "‚óè Some incomplete or missing data\n",
        "Explain the approach you would take to:\n",
        "‚óè Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "‚óè Choose and justify an appropriate model (SVM vs. Na√Øve Bayes)\n",
        "‚óè Address class imbalance\n",
        "‚óè Evaluate the performance of your solution with suitable metrics\n",
        "And explain the business impact of your solution.\n"
      ],
      "metadata": {
        "id": "MroV_FlzHWcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preprocessing\n",
        "üìÑ Text Vectorization\n",
        "- Tokenization: Break emails into words or tokens.\n",
        "\n",
        "- Stopword Removal: Eliminate common words (e.g., \"the\", \"is\") that add little value.\n",
        "\n",
        "- Stemming/Lemmatization: Normalize words to their root forms.\n",
        "\n",
        "- Vectorization Techniques:\n",
        "\n",
        "  - TF-IDF: Captures word importance across documents.\n",
        "\n",
        "  - CountVectorizer: Simple word frequency representation.\n",
        "\n",
        "  - Consider n-grams (e.g., bigrams) to capture word sequences.\n",
        "\n",
        "Handling Missing Data\n",
        "- Missing Text: Replace with a placeholder like \"empty\" or remove if rare.\n",
        "\n",
        "- Missing Metadata (e.g., sender info): Impute with mode or flag as unknown.\n",
        "\n",
        "- Feature Engineering: Create binary indicators for missing fields."
      ],
      "metadata": {
        "id": "uFRlRkFTHc4c"
      }
    }
  ]
}